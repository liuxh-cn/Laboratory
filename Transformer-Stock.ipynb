{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考自NLP代码 [PyTorch快餐教程2019 (1) - 从Transformer说起](https://blog.csdn.net/lusing/article/details/102666617/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import sys\n",
    "sys.path.append(r'./')\n",
    "from AModelFactory import ModelFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''全局参数'''\n",
    "r_train = 0.9\n",
    "\n",
    "batch_size = 20 \n",
    "seq_len = 35    \n",
    "emsize = 6\n",
    "\n",
    "nhid = 256      # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2     # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2       # the number of heads in the multiheadattention models\n",
    "dropout = 0.2   # the dropout value\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "      <th>money</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-04-08</th>\n",
       "      <td>984.66</td>\n",
       "      <td>1003.45</td>\n",
       "      <td>1003.70</td>\n",
       "      <td>979.53</td>\n",
       "      <td>1.476253e+09</td>\n",
       "      <td>9.151350e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-11</th>\n",
       "      <td>1003.88</td>\n",
       "      <td>995.42</td>\n",
       "      <td>1008.74</td>\n",
       "      <td>992.77</td>\n",
       "      <td>1.593607e+09</td>\n",
       "      <td>1.043623e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-12</th>\n",
       "      <td>993.71</td>\n",
       "      <td>978.70</td>\n",
       "      <td>993.71</td>\n",
       "      <td>978.20</td>\n",
       "      <td>1.022619e+09</td>\n",
       "      <td>6.479563e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-13</th>\n",
       "      <td>987.95</td>\n",
       "      <td>1000.90</td>\n",
       "      <td>1006.50</td>\n",
       "      <td>987.95</td>\n",
       "      <td>1.607169e+09</td>\n",
       "      <td>1.002960e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-14</th>\n",
       "      <td>1004.64</td>\n",
       "      <td>986.98</td>\n",
       "      <td>1006.42</td>\n",
       "      <td>985.58</td>\n",
       "      <td>1.294571e+09</td>\n",
       "      <td>7.813425e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-25</th>\n",
       "      <td>3832.09</td>\n",
       "      <td>3838.20</td>\n",
       "      <td>3848.03</td>\n",
       "      <td>3813.20</td>\n",
       "      <td>1.196240e+10</td>\n",
       "      <td>1.633145e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-28</th>\n",
       "      <td>3847.53</td>\n",
       "      <td>3727.63</td>\n",
       "      <td>3853.39</td>\n",
       "      <td>3727.63</td>\n",
       "      <td>1.539884e+10</td>\n",
       "      <td>2.100260e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-29</th>\n",
       "      <td>3723.05</td>\n",
       "      <td>3761.88</td>\n",
       "      <td>3762.05</td>\n",
       "      <td>3710.48</td>\n",
       "      <td>1.018856e+10</td>\n",
       "      <td>1.404051e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-30</th>\n",
       "      <td>3762.91</td>\n",
       "      <td>3765.18</td>\n",
       "      <td>3765.66</td>\n",
       "      <td>3726.28</td>\n",
       "      <td>1.056300e+10</td>\n",
       "      <td>1.557441e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-31</th>\n",
       "      <td>3760.90</td>\n",
       "      <td>3731.01</td>\n",
       "      <td>3772.62</td>\n",
       "      <td>3727.32</td>\n",
       "      <td>1.018736e+10</td>\n",
       "      <td>1.450437e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2610 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               open    close     high      low        volume         money\n",
       "2005-04-08   984.66  1003.45  1003.70   979.53  1.476253e+09  9.151350e+09\n",
       "2005-04-11  1003.88   995.42  1008.74   992.77  1.593607e+09  1.043623e+10\n",
       "2005-04-12   993.71   978.70   993.71   978.20  1.022619e+09  6.479563e+09\n",
       "2005-04-13   987.95  1000.90  1006.50   987.95  1.607169e+09  1.002960e+10\n",
       "2005-04-14  1004.64   986.98  1006.42   985.58  1.294571e+09  7.813425e+09\n",
       "...             ...      ...      ...      ...           ...           ...\n",
       "2015-12-25  3832.09  3838.20  3848.03  3813.20  1.196240e+10  1.633145e+11\n",
       "2015-12-28  3847.53  3727.63  3853.39  3727.63  1.539884e+10  2.100260e+11\n",
       "2015-12-29  3723.05  3761.88  3762.05  3710.48  1.018856e+10  1.404051e+11\n",
       "2015-12-30  3762.91  3765.18  3765.66  3726.28  1.056300e+10  1.557441e+11\n",
       "2015-12-31  3760.90  3731.01  3772.62  3727.32  1.018736e+10  1.450437e+11\n",
       "\n",
       "[2610 rows x 6 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''1. 读取数据，选择需要的列'''\n",
    "data = pd.read_csv('XSHG300.csv', index_col=0)  # , parse_dates=True\n",
    "data = data[['open', 'close', 'high', 'low', 'volume', 'money']]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20050408, 20050411, 20050412,  ..., 20141204, 20141205, 20141208])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''2.1 划分\"训练集、测试集\"；构造“序列 - trian_seq/test_seq” '''\n",
    "data_seq = list(data.index)\n",
    "data_seq = list(map(lambda x: int(x.replace('-', '')), data_seq))   # Tensor只接受数值数据\n",
    "data_seq = torch.tensor(data_seq)\n",
    "data.index = data_seq\n",
    "\n",
    "train_len = int(0.9*len(data_seq))\n",
    "train_seq = data_seq[:train_len]\n",
    "train_data = data[:train_len]\n",
    "\n",
    "train_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "      <th>money</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20050408</th>\n",
       "      <td>-1.594964</td>\n",
       "      <td>-1.579738</td>\n",
       "      <td>-1.584240</td>\n",
       "      <td>-1.598419</td>\n",
       "      <td>-1.132051</td>\n",
       "      <td>-1.217806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20050411</th>\n",
       "      <td>-1.575985</td>\n",
       "      <td>-1.587671</td>\n",
       "      <td>-1.579326</td>\n",
       "      <td>-1.585116</td>\n",
       "      <td>-1.102353</td>\n",
       "      <td>-1.190584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20050412</th>\n",
       "      <td>-1.586027</td>\n",
       "      <td>-1.604188</td>\n",
       "      <td>-1.593979</td>\n",
       "      <td>-1.599756</td>\n",
       "      <td>-1.246846</td>\n",
       "      <td>-1.274410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20050413</th>\n",
       "      <td>-1.591715</td>\n",
       "      <td>-1.582257</td>\n",
       "      <td>-1.581510</td>\n",
       "      <td>-1.589959</td>\n",
       "      <td>-1.098921</td>\n",
       "      <td>-1.199199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20050414</th>\n",
       "      <td>-1.575234</td>\n",
       "      <td>-1.596008</td>\n",
       "      <td>-1.581588</td>\n",
       "      <td>-1.592340</td>\n",
       "      <td>-1.178027</td>\n",
       "      <td>-1.246151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20151225</th>\n",
       "      <td>1.216760</td>\n",
       "      <td>1.220656</td>\n",
       "      <td>1.188694</td>\n",
       "      <td>1.248826</td>\n",
       "      <td>1.521554</td>\n",
       "      <td>2.048287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20151228</th>\n",
       "      <td>1.232006</td>\n",
       "      <td>1.111426</td>\n",
       "      <td>1.193919</td>\n",
       "      <td>1.162847</td>\n",
       "      <td>2.391173</td>\n",
       "      <td>3.037915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20151229</th>\n",
       "      <td>1.109087</td>\n",
       "      <td>1.145261</td>\n",
       "      <td>1.104872</td>\n",
       "      <td>1.145614</td>\n",
       "      <td>1.072668</td>\n",
       "      <td>1.562929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20151230</th>\n",
       "      <td>1.148448</td>\n",
       "      <td>1.148521</td>\n",
       "      <td>1.108391</td>\n",
       "      <td>1.161490</td>\n",
       "      <td>1.167423</td>\n",
       "      <td>1.887901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20151231</th>\n",
       "      <td>1.146463</td>\n",
       "      <td>1.114765</td>\n",
       "      <td>1.115177</td>\n",
       "      <td>1.162535</td>\n",
       "      <td>1.072364</td>\n",
       "      <td>1.661203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2610 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              open     close      high       low    volume     money\n",
       "20050408 -1.594964 -1.579738 -1.584240 -1.598419 -1.132051 -1.217806\n",
       "20050411 -1.575985 -1.587671 -1.579326 -1.585116 -1.102353 -1.190584\n",
       "20050412 -1.586027 -1.604188 -1.593979 -1.599756 -1.246846 -1.274410\n",
       "20050413 -1.591715 -1.582257 -1.581510 -1.589959 -1.098921 -1.199199\n",
       "20050414 -1.575234 -1.596008 -1.581588 -1.592340 -1.178027 -1.246151\n",
       "...            ...       ...       ...       ...       ...       ...\n",
       "20151225  1.216760  1.220656  1.188694  1.248826  1.521554  2.048287\n",
       "20151228  1.232006  1.111426  1.193919  1.162847  2.391173  3.037915\n",
       "20151229  1.109087  1.145261  1.104872  1.145614  1.072668  1.562929\n",
       "20151230  1.148448  1.148521  1.108391  1.161490  1.167423  1.887901\n",
       "20151231  1.146463  1.114765  1.115177  1.162535  1.072364  1.661203\n",
       "\n",
       "[2610 rows x 6 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''2.2 归一化；构造\"字典 - Dict\" '''\n",
    "scaler = StandardScaler().fit(train_data)\n",
    "data_norm = scaler.transform(data)\n",
    "Dict = DataFrame(data_norm, index=data.index, columns=data.columns)\n",
    "\n",
    "Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''3. 模型训练的准备'''\n",
    "'''扩展出seq_len\n",
    "'''\n",
    "def get_batch(source, i):\n",
    "\n",
    "    real_seq_len = min(seq_len, len(source) - 1 - i)\n",
    "\n",
    "    data = source[i:i + real_seq_len]\n",
    "    target = source[i + 1:i + 1 + real_seq_len].view(-1)\n",
    "    # 输入的查表在模型中做的，考虑都移到这里\n",
    "    data = ...\n",
    "    target = torch.tensor(list(map(lambda x: Dict.loc[int(x)]['close'], target)), dtype=torch.float32)\n",
    "\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelFactory.createTransformer(Dict, emsize, nhead, nhid, nlayers, dropout).to(device)\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()  # Turn on the train mode\n",
    "\n",
    "    total_loss = 0.\n",
    "    n = 0\n",
    "    for batch, i in enumerate(range(0, train_seq.size(0) - 1, bptt)):\n",
    "\n",
    "        data, targets = get_batch(train_seq, i)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data)\n",
    "        \n",
    "        output = torch.squeeze(output)\n",
    "        loss = loss_func(output.view(-1), targets)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        n += len(targets)\n",
    "\n",
    "    return total_loss / n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before epoch\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ellipsis' object has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-c8b9f9437e0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-136-af5d28f88871>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/code/python/workspace-jupyter/AModelFactory.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memsize\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ninp = embedding dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;31m# word_embedding + position_embedding           [35, 20, 200]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ellipsis' object has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "epochs = 100  # The number of epochs\n",
    "print(\"before epoch\")\n",
    "x = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    total_loss = train()\n",
    "    print(total_loss)\n",
    "    x.append(total_loss)\n",
    "    optimizer.step()\n",
    "torch.save(model, './rnn.pkl')\n",
    "\n",
    "plt.plot(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
